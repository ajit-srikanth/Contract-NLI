{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9908541,"sourceType":"datasetVersion","datasetId":6087842},{"sourceId":171987,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":146392,"modelId":168930}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-11-20T14:21:35.003115Z","iopub.execute_input":"2024-11-20T14:21:35.004047Z","iopub.status.idle":"2024-11-20T14:21:35.036348Z","shell.execute_reply.started":"2024-11-20T14:21:35.004010Z","shell.execute_reply":"2024-11-20T14:21:35.035342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install sentence_transformers","metadata":{"execution":{"iopub.status.busy":"2024-11-20T14:21:35.333060Z","iopub.execute_input":"2024-11-20T14:21:35.333403Z","iopub.status.idle":"2024-11-20T14:21:45.817817Z","shell.execute_reply.started":"2024-11-20T14:21:35.333370Z","shell.execute_reply":"2024-11-20T14:21:45.816699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nsentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n\nmodel = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\nembeddings = model.encode(sentences)\nprint(embeddings.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:18.495579Z","iopub.execute_input":"2024-11-19T19:55:18.495959Z","iopub.status.idle":"2024-11-19T19:55:38.947445Z","shell.execute_reply.started":"2024-11-19T19:55:18.495917Z","shell.execute_reply":"2024-11-19T19:55:38.946556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Load JSON data from a file\nwith open('/kaggle/input/anlp-project-contract-nli/train.json', 'r') as file:\n    data = json.load(file)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:38.949175Z","iopub.execute_input":"2024-11-19T19:55:38.949726Z","iopub.status.idle":"2024-11-19T19:55:39.467847Z","shell.execute_reply.started":"2024-11-19T19:55:38.949698Z","shell.execute_reply":"2024-11-19T19:55:39.466780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\nstart_time = time.time()\n\nlabels = data['labels']\nlabel_texts = {}\nfor key, item in labels.items():\n    label_texts[key] = item['hypothesis']\n\nlabel_embedding = {}\nfor key, item in label_texts.items():\n    label_embedding[key] = model.encode(item)\n\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(f\"Execution time: {execution_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:39.469722Z","iopub.execute_input":"2024-11-19T19:55:39.470043Z","iopub.status.idle":"2024-11-19T19:55:39.837524Z","shell.execute_reply.started":"2024-11-19T19:55:39.470012Z","shell.execute_reply":"2024-11-19T19:55:39.836691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=data['labels']\nlabel_texts={}\nfor key, item in labels.items():\n    label_texts[key]=item['hypothesis']\nlabel_embedding={}\nfor key, item in label_texts.items():\n    label_embedding[key]=model.encode(item)\n# print(label_embedding)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:39.838791Z","iopub.execute_input":"2024-11-19T19:55:39.839482Z","iopub.status.idle":"2024-11-19T19:55:40.197109Z","shell.execute_reply.started":"2024-11-19T19:55:39.839442Z","shell.execute_reply":"2024-11-19T19:55:40.196293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evidence_spans_per_document = {}\nfor document in data['documents']:\n    hypothesis_to_span = {}\n    annotations = document['annotation_sets'][0]['annotations']\n\n    for key, annotation in annotations.items():\n        # print(f\"Key: {key}, Annotation: {annotation}\")\n        hypothesis_to_span[key] = annotation['spans']\n    evidence_spans_per_document[document['id']] = hypothesis_to_span\n# print(evidence_spans_per_document)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.198205Z","iopub.execute_input":"2024-11-19T19:55:40.198459Z","iopub.status.idle":"2024-11-19T19:55:40.204957Z","shell.execute_reply.started":"2024-11-19T19:55:40.198434Z","shell.execute_reply":"2024-11-19T19:55:40.204079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset={}\nfor document in data['documents']:\n    for index,span in enumerate(document['spans']):\n        dataset[document['text'][span[0]:span[1]]]='null'","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.206051Z","iopub.execute_input":"2024-11-19T19:55:40.206352Z","iopub.status.idle":"2024-11-19T19:55:40.239817Z","shell.execute_reply.started":"2024-11-19T19:55:40.206327Z","shell.execute_reply":"2024-11-19T19:55:40.239129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for document in data['documents']:\n    for index,span in enumerate(document['spans']):\n        for key, spans in evidence_spans_per_document[document['id']].items():\n            if index in spans:\n                dataset[document['text'][span[0]:span[1]]]=key\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.240933Z","iopub.execute_input":"2024-11-19T19:55:40.241263Z","iopub.status.idle":"2024-11-19T19:55:40.318464Z","shell.execute_reply.started":"2024-11-19T19:55:40.241226Z","shell.execute_reply":"2024-11-19T19:55:40.317785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(dataset))","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.321040Z","iopub.execute_input":"2024-11-19T19:55:40.321298Z","iopub.status.idle":"2024-11-19T19:55:40.326126Z","shell.execute_reply.started":"2024-11-19T19:55:40.321273Z","shell.execute_reply":"2024-11-19T19:55:40.325023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = data['labels']\nlabel_texts = {}\nfor key, item in labels.items():\n    label_texts[key] = item['hypothesis']\n\n# print(label_texts)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.327377Z","iopub.execute_input":"2024-11-19T19:55:40.327917Z","iopub.status.idle":"2024-11-19T19:55:40.334671Z","shell.execute_reply.started":"2024-11-19T19:55:40.327872Z","shell.execute_reply":"2024-11-19T19:55:40.333753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_embedding = {}\nfor key, item in label_texts.items():\n    label_embedding[key] = model.encode(item)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.335856Z","iopub.execute_input":"2024-11-19T19:55:40.336461Z","iopub.status.idle":"2024-11-19T19:55:40.697445Z","shell.execute_reply.started":"2024-11-19T19:55:40.336422Z","shell.execute_reply":"2024-11-19T19:55:40.696584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_keys = list(data['labels'].keys())","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.698485Z","iopub.execute_input":"2024-11-19T19:55:40.698731Z","iopub.status.idle":"2024-11-19T19:55:40.702724Z","shell.execute_reply.started":"2024-11-19T19:55:40.698706Z","shell.execute_reply":"2024-11-19T19:55:40.701818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_dataset = []\nfor key, item in dataset.items():\n    for label_key in label_keys:\n        if item == label_key:\n            final_dataset.append((key, data['labels'][label_key]['hypothesis'], 1))\n        else:\n            final_dataset.append((key, data['labels'][label_key]['hypothesis'], 0))","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.703754Z","iopub.execute_input":"2024-11-19T19:55:40.704015Z","iopub.status.idle":"2024-11-19T19:55:40.876770Z","shell.execute_reply.started":"2024-11-19T19:55:40.703991Z","shell.execute_reply":"2024-11-19T19:55:40.875884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(final_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.878211Z","iopub.execute_input":"2024-11-19T19:55:40.878498Z","iopub.status.idle":"2024-11-19T19:55:40.882602Z","shell.execute_reply.started":"2024-11-19T19:55:40.878471Z","shell.execute_reply":"2024-11-19T19:55:40.881781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SentenceDataset(Dataset):\n    def __init__(self, final_dataset):\n        self.data = final_dataset\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        sentence, hypothesis, label = self.data[idx]\n        return sentence, hypothesis, torch.tensor(label, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.883607Z","iopub.execute_input":"2024-11-19T19:55:40.883931Z","iopub.status.idle":"2024-11-19T19:55:40.894351Z","shell.execute_reply.started":"2024-11-19T19:55:40.883905Z","shell.execute_reply":"2024-11-19T19:55:40.893606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sentence_transformers import SentenceTransformer\n\n\nclass SimilarityClassifier(nn.Module):\n    def __init__(self, model_name='sentence-transformers/all-MiniLM-L12-v2'):\n        super().__init__()\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.encoder = SentenceTransformer(model_name)\n        \n        # Unfreeze encoder parameters\n        for param in self.encoder.parameters():\n            param.requires_grad = True\n        \n        self.encoder.to(self.device)\n        \n        self.embedding_dim = self.encoder.get_sentence_embedding_dimension()\n        \n        # Neural network taking concatenated embeddings\n        self.classifier = nn.Sequential(\n            nn.Linear(self.embedding_dim * 2, 512),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 1),\n            nn.Sigmoid()\n        ).to(self.device)\n        # self.threshold = nn.Parameter(torch.tensor([init_threshold], device=self.device))\n\n    def encode_text(self, sentences):\n        # Enable gradients for encoding\n        embeddings = self.encoder.encode(sentences, convert_to_tensor=True,show_progress_bar = False)\n        return embeddings.to(self.device)\n\n    def forward(self, sentences, hypothesis):\n        # Encode input sentences\n        if isinstance(sentences, tuple):\n            sentences = list(sentences)\n        \n        if isinstance(hypothesis,tuple):\n            hypothesis=list(hypothesis)\n        \n        \n        sentence_embeddings = self.encode_text(sentences)\n        hypothesis_embedding = self.encode_text(hypothesis)\n        \n        # Concatenate embeddings\n        combined = torch.cat((sentence_embeddings, hypothesis_embedding), dim=1)\n        \n        # Get predictions from neural network\n        predictions = self.classifier(combined)\n        return predictions.squeeze(), None\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T14:22:58.946922Z","iopub.execute_input":"2024-11-20T14:22:58.947634Z","iopub.status.idle":"2024-11-20T14:22:58.957408Z","shell.execute_reply.started":"2024-11-20T14:22:58.947598Z","shell.execute_reply":"2024-11-20T14:22:58.956367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training setup with different learning rates\ndef get_optimizer(model):\n    encoder_params = model.encoder.parameters()\n    classifier_params = model.classifier.parameters()\n    \n    return torch.optim.AdamW([\n        {'params': encoder_params, 'lr': 1e-5},  # Lower learning rate for encoder\n        {'params': classifier_params, 'lr': 1e-3} # Higher learning rate for classifier\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.907640Z","iopub.execute_input":"2024-11-19T19:55:40.907905Z","iopub.status.idle":"2024-11-19T19:55:40.919771Z","shell.execute_reply.started":"2024-11-19T19:55:40.907881Z","shell.execute_reply":"2024-11-19T19:55:40.918994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Training function\nfrom tqdm.auto import tqdm\ndef train_model(model, final_dataset, num_epochs=10, batch_size=64, lr=1e-3):\n    # Create dataset and dataloader\n    dataset = SentenceDataset(final_dataset)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    # Setup training\n#     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    criterion = torch.nn.BCELoss()\n    \n    model = model.to(device)\n    optimizer = get_optimizer(model)\n    # Training loop\n    for epoch in tqdm(range(num_epochs)):\n        model.train()\n        total_loss = 0\n        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n        \n        for batch_sentences, batch_hypotheses, batch_labels in tqdm(dataloader):\n            optimizer.zero_grad()\n            \n            batch_labels = batch_labels.to(device)\n            # Forward pass\n            predictions, _ = model(batch_sentences, batch_hypotheses)\n            loss = criterion(predictions, batch_labels)\n            \n            # Backward pass\n#             loss.requires_grad = True\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n#             progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n        \n        avg_loss = total_loss / len(dataloader)\n        print(f'Epoch {epoch+1} - Average Loss: {avg_loss:.4f}')\n#         print(f'Current threshold: {torch.sigmoid(torch.tensor(model.threshold.item())):.4f}')\n\n# Usage\nmodel = SimilarityClassifier()\ntrain_model(model, final_dataset)\ntorch.save(model.state_dict(), \"model.pt\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T19:55:40.920724Z","iopub.execute_input":"2024-11-19T19:55:40.920990Z","iopub.status.idle":"2024-11-19T19:56:15.217970Z","shell.execute_reply.started":"2024-11-19T19:55:40.920966Z","shell.execute_reply":"2024-11-19T19:56:15.215560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = SimilarityClassifier()\nmodel.load_state_dict(torch.load(\"/kaggle/input/anlpproject/pytorch/default/1/model.pt\"))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:16.576409Z","iopub.execute_input":"2024-11-20T15:01:16.577446Z","iopub.status.idle":"2024-11-20T15:01:17.632288Z","shell.execute_reply.started":"2024-11-20T15:01:16.577395Z","shell.execute_reply":"2024-11-20T15:01:17.631267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# Load JSON data from a file\nwith open('/kaggle/input/anlp-project-contract-nli/test.json', 'r') as file:\n    test_data = json.load(file)\n    \n    \n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.633720Z","iopub.execute_input":"2024-11-20T15:01:17.634001Z","iopub.status.idle":"2024-11-20T15:01:17.656099Z","shell.execute_reply.started":"2024-11-20T15:01:17.633974Z","shell.execute_reply":"2024-11-20T15:01:17.655299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evidence_spans_per_document = {}\nfor document in test_data['documents']:\n    hypothesis_to_span = {}\n    annotations = document['annotation_sets'][0]['annotations']\n\n    for key, annotation in annotations.items():\n        # print(f\"Key: {key}, Annotation: {annotation}\")\n        hypothesis_to_span[key] = (annotation['spans'],annotation['choice'])\n    evidence_spans_per_document[document['id']] = hypothesis_to_span\n# print(evidence_spans_per_document)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.657351Z","iopub.execute_input":"2024-11-20T15:01:17.657745Z","iopub.status.idle":"2024-11-20T15:01:17.665382Z","shell.execute_reply.started":"2024-11-20T15:01:17.657695Z","shell.execute_reply":"2024-11-20T15:01:17.664324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset={}\nfor document in test_data['documents']:\n    for index,span in enumerate(document['spans']):\n        test_dataset[document['text'][span[0]:span[1]]]=(document['id'],'null', 'null')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.667239Z","iopub.execute_input":"2024-11-20T15:01:17.667611Z","iopub.status.idle":"2024-11-20T15:01:17.687952Z","shell.execute_reply.started":"2024-11-20T15:01:17.667581Z","shell.execute_reply":"2024-11-20T15:01:17.686919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.689231Z","iopub.execute_input":"2024-11-20T15:01:17.689688Z","iopub.status.idle":"2024-11-20T15:01:17.700259Z","shell.execute_reply.started":"2024-11-20T15:01:17.689659Z","shell.execute_reply":"2024-11-20T15:01:17.699297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for document in test_data['documents']:\n    for index,span in enumerate(document['spans']):\n        for key, items in evidence_spans_per_document[document['id']].items():\n            if index in items[0]:\n                test_dataset[document['text'][span[0]:span[1]]]=(document['id'],key,items[1])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.701338Z","iopub.execute_input":"2024-11-20T15:01:17.701645Z","iopub.status.idle":"2024-11-20T15:01:17.743429Z","shell.execute_reply.started":"2024-11-20T15:01:17.701603Z","shell.execute_reply":"2024-11-20T15:01:17.742474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_dataset))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.744671Z","iopub.execute_input":"2024-11-20T15:01:17.744976Z","iopub.status.idle":"2024-11-20T15:01:17.749946Z","shell.execute_reply.started":"2024-11-20T15:01:17.744948Z","shell.execute_reply":"2024-11-20T15:01:17.748963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:17.751185Z","iopub.execute_input":"2024-11-20T15:01:17.751582Z","iopub.status.idle":"2024-11-20T15:01:18.513566Z","shell.execute_reply.started":"2024-11-20T15:01:17.751541Z","shell.execute_reply":"2024-11-20T15:01:18.512462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = test_data['labels']\nlabel_texts = {}\nfor key, item in labels.items():\n    label_texts[key] = item['hypothesis']\n\nlabel_embedding = {}\nfor key, item in label_texts.items():\n    label_embedding[key] = temp_model.encode(item)\n\nlabel_keys = list(test_data['labels'].keys())\n# print(label_keys)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:18.514855Z","iopub.execute_input":"2024-11-20T15:01:18.515173Z","iopub.status.idle":"2024-11-20T15:01:18.925685Z","shell.execute_reply.started":"2024-11-20T15:01:18.515140Z","shell.execute_reply":"2024-11-20T15:01:18.924778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_test_dataset = []\nfor key, item in test_dataset.items():\n    for label_key in label_keys:\n        if item[1] == label_key:\n            final_test_dataset.append((item[0], key,  test_data['labels'][label_key]['hypothesis'], 1, item[2]))\n        else:\n            final_test_dataset.append((item[0], key,  test_data['labels'][label_key]['hypothesis'], 0, 'null'))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:18.929471Z","iopub.execute_input":"2024-11-20T15:01:18.930158Z","iopub.status.idle":"2024-11-20T15:01:19.002914Z","shell.execute_reply.started":"2024-11-20T15:01:18.930116Z","shell.execute_reply":"2024-11-20T15:01:19.002143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nrandom.seed(42)  # Python's built-in random\n\n# Calculate size for 10% of data\nsample_size = int(0.1 * len(final_test_dataset))\n\n# Randomly sample indices\nsampled_indices = random.sample(range(len(final_test_dataset)), sample_size)\n\n# Create new dataset with sampled elements\nfinal_test_dataset = [final_test_dataset[i] for i in sampled_indices]\n\nprint(f\"Original dataset size: {len(final_test_dataset) * 10}\")\nprint(f\"Sampled dataset size: {len(final_test_dataset)}\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:19.003764Z","iopub.execute_input":"2024-11-20T15:01:19.004036Z","iopub.status.idle":"2024-11-20T15:01:19.029517Z","shell.execute_reply.started":"2024-11-20T15:01:19.004009Z","shell.execute_reply":"2024-11-20T15:01:19.028485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positives=[]\nnegatives=[]\ntotal_spans={}\ntrue_spans={}\nfalse_spans={}\n\nglobal Total_entailment, Total_contradiction, predicted_entailment, predicted_contradiction\nTotal_entailment = 0\nTotal_contradiction = 0\npredicted_entailment = 0\npredicted_contradiction = 0\n\nfinal_evidence_dataset=[]\ndef evaluate_model(model, test_dataset, threshold=None):\n    # Initialize metrics\n    true_positives = 0\n    false_positives = 0\n    true_negatives = 0\n    false_negatives = 0\n    \n    # Set model to evaluation mode\n    model.eval()\n    threshold = 0.003 \n    global Total_entailment, Total_contradiction, predicted_entailment, predicted_contradiction\n\n    with torch.no_grad():\n        for doc_id, sentence, hypothesis, true_label, inference in tqdm(test_dataset, position=0, leave=True):\n            # Get model predictions\n            pred, _ = model([sentence], [hypothesis])\n            predicted_label = pred.item()\n#             true_label = true_label.item()\n\n            if true_label == 1:\n                positives.append(predicted_label)\n            else:\n                negatives.append(predicted_label)\n                \n            predicted_label = 1 if predicted_label >= threshold else 0\n            true_label = 1 if true_label >= threshold else 0\n            \n            if predicted_label == 1:\n                final_evidence_dataset.append((doc_id, sentence, hypothesis, true_label,inference))\n            \n            if inference==\"Entailment\":\n                Total_entailment+=1\n                if predicted_label==1:\n                    predicted_entailment+=1\n            elif inference==\"Contradiction\":\n                Total_contradiction+=1\n                if predicted_label==1:\n                    predicted_contradiction+=1\n                    \n            # Update confusion matrix\n            if predicted_label == 1 and true_label == 1:\n                true_positives += 1\n                total_spans[sentence]=True\n                true_spans[sentence]=True\n            elif predicted_label == 1 and true_label == 0:\n                false_positives += 1\n                total_spans[sentence]=True\n                false_spans[sentence]=True\n            elif predicted_label == 0 and true_label == 0:\n                true_negatives += 1\n            else:\n                false_negatives += 1\n    \n    # Calculate metrics\n    total = len(test_dataset)\n    accuracy = (true_positives + true_negatives) / total\n    \n    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    # Print results\n    print(\"\\nConfusion Matrix:\")\n    print(f\"True Positives: {true_positives}\")\n    print(f\"False Positives: {false_positives}\")\n    print(f\"True Negatives: {true_negatives}\")\n    print(f\"False Negatives: {false_negatives}\")\n    \n    print(\"\\nMetrics:\")\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    \n    return {\n        'confusion_matrix': {\n            'tp': true_positives,\n            'fp': false_positives,\n            'tn': true_negatives,\n            'fn': false_negatives\n        },\n        'metrics': {\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1': f1\n        }\n    }\n\n# Usage\nresults = evaluate_model(model, final_test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:01:19.031210Z","iopub.execute_input":"2024-11-20T15:01:19.031742Z","iopub.status.idle":"2024-11-20T15:06:56.860043Z","shell.execute_reply.started":"2024-11-20T15:01:19.031694Z","shell.execute_reply":"2024-11-20T15:06:56.858948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(Total_entailment)\nprint(Total_contradiction)\nprint(predicted_entailment)\nprint(predicted_contradiction)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:56.861819Z","iopub.execute_input":"2024-11-20T15:06:56.862251Z","iopub.status.idle":"2024-11-20T15:06:56.867943Z","shell.execute_reply.started":"2024-11-20T15:06:56.862187Z","shell.execute_reply":"2024-11-20T15:06:56.866941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('final_evidence_dataset.json', 'w') as file:\n    json.dump(final_evidence_dataset, file)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:56.869114Z","iopub.execute_input":"2024-11-20T15:06:56.869431Z","iopub.status.idle":"2024-11-20T15:06:56.894745Z","shell.execute_reply.started":"2024-11-20T15:06:56.869403Z","shell.execute_reply":"2024-11-20T15:06:56.893823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(total_spans))\nprint(len(true_spans))\nprint((false_spans))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:56.895870Z","iopub.execute_input":"2024-11-20T15:06:56.896251Z","iopub.status.idle":"2024-11-20T15:06:56.907618Z","shell.execute_reply.started":"2024-11-20T15:06:56.896209Z","shell.execute_reply":"2024-11-20T15:06:56.906478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(negatives))","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:56.908773Z","iopub.execute_input":"2024-11-20T15:06:56.909055Z","iopub.status.idle":"2024-11-20T15:06:56.920253Z","shell.execute_reply.started":"2024-11-20T15:06:56.909027Z","shell.execute_reply":"2024-11-20T15:06:56.919346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Create subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Plot histograms\nax1.hist(positives, bins=100, alpha=0.7, color='blue')\nax1.set_title('Histogram of Array 1')\nax1.set_xlabel('Values')\nax1.set_ylabel('Frequency')\n\nax2.hist(negatives, bins=100, alpha=0.7, color='green')\nax2.set_title('Histogram of Array 2')\nax2.set_xlabel('Values')\nax2.set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:56.921329Z","iopub.execute_input":"2024-11-20T15:06:56.921587Z","iopub.status.idle":"2024-11-20T15:06:57.817857Z","shell.execute_reply.started":"2024-11-20T15:06:56.921562Z","shell.execute_reply":"2024-11-20T15:06:57.816898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npositives_np=np.array(positives, dtype=float)\nnegatives_np=np.array(negatives, dtype=float)\npositives_new=positives_np[positives_np<0.005]\nnegatives_new=negatives_np[negatives_np<0.005]\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:57.819217Z","iopub.execute_input":"2024-11-20T15:06:57.819625Z","iopub.status.idle":"2024-11-20T15:06:57.827304Z","shell.execute_reply.started":"2024-11-20T15:06:57.819583Z","shell.execute_reply":"2024-11-20T15:06:57.826110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create subplots\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# Plot histograms\nax1.hist(positives_new, bins=100, alpha=0.7, color='blue')\nax1.set_title('Histogram of Array 1')\nax1.set_xlabel('Values')\nax1.set_ylabel('Frequency')\n\nax2.hist(negatives_new, bins=100, alpha=0.7, color='green')\nax2.set_title('Histogram of Array 2')\nax2.set_xlabel('Values')\nax2.set_ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:57.828622Z","iopub.execute_input":"2024-11-20T15:06:57.828914Z","iopub.status.idle":"2024-11-20T15:06:58.511690Z","shell.execute_reply.started":"2024-11-20T15:06:57.828886Z","shell.execute_reply":"2024-11-20T15:06:58.510541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create histogram data\ncounts, bins = np.histogram(negatives_new, bins=20)\ncumulative = np.cumsum(counts)\n\n# Plot cumulative histogram\nplt.figure(figsize=(10, 6))\nplt.hist(negatives_new, bins=1000, density=True, cumulative=True, \n         histtype='step', label='Cumulative', color='blue')\nplt.hist(positives_new, bins=1000, density=True, cumulative=True, \n         histtype='step', label='Cumulative', color='orange')\nplt.grid(True, alpha=0.3)\nplt.xticks(np.arange(0, 0.011, 0.005))  # Labels from 0 to 1 in steps of 0.05\nplt.xticks(rotation=45)  \nplt.xlabel('Values')\nplt.ylabel('Cumulative Frequency')\nplt.title('Cumulative Histogram')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:58.513045Z","iopub.execute_input":"2024-11-20T15:06:58.513442Z","iopub.status.idle":"2024-11-20T15:06:58.900109Z","shell.execute_reply.started":"2024-11-20T15:06:58.513402Z","shell.execute_reply":"2024-11-20T15:06:58.899187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f'Total Parameters: {total_params:,}')\n    print(f'Trainable Parameters: {trainable_params:,}')\n    \n    # Print breakdown by component\n    print('\\nParameter breakdown:')\n    for name, param in model.named_parameters():\n        print(f'{name}: {param.numel():,} parameters')\n\n# Call function on model\ncount_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:06:58.901585Z","iopub.execute_input":"2024-11-20T15:06:58.901999Z","iopub.status.idle":"2024-11-20T15:06:58.912686Z","shell.execute_reply.started":"2024-11-20T15:06:58.901955Z","shell.execute_reply":"2024-11-20T15:06:58.911641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}